{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vasWnqRgy1H4"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 Fran√ßois Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Basic classification: Classify images of clothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "And the model predicts a label as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model1: NN\n",
        "\n",
        "Create a model to have an image of 28*28 pixels as an input with 10 output classes.\n",
        "\n",
        "The model composes of flatten, dropout 20%, dense with 128 neurons, and output layer to classify each image into 10 classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "tXzliHOURDw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Insert your code here\n",
        "'''"
      ],
      "metadata": {
        "id": "t95-wj_lROGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "z4WqE9KwRdMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_images, train_labels,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "TEqjmc0ORowV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "Tfm3uX6KSc3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict values from test set\n",
        "y_pred = model.predict(test_images)\n",
        "#convert predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "#convert test observations to one hot vectors\n",
        "#y_true = np.argmax(test_labels)\n",
        "y_true = test_labels\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes,  target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "RjOenjlgSjIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model2: CNN\n",
        "\n",
        "Modify Model1:\n",
        "\n",
        "Before the flatten layer, add 2 layers of Conv2D with kernel(2*2) for 64 and 32 filters, respectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "JCnfdc00T8WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Insert your code here\n",
        "'''"
      ],
      "metadata": {
        "id": "m0VfUAfUUJm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "k31cTHIXUWVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_images, train_labels,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "TMeNp7tDZQD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "N9c7sW0MVTvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict values from test set\n",
        "y_pred = model.predict(test_images)\n",
        "#convert predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "#convert test observations to one hot vectors\n",
        "#y_true = np.argmax(test_labels)\n",
        "y_true = test_labels\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes,  target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "QtR1fR3wVVpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model3: CNN with max-pool & dropout\n",
        "\n",
        "From those two Conv2D layers in Model2, add MaxPooling2D with pooling size (2*2) and then dropout 30%."
      ],
      "metadata": {
        "id": "pGzkCapqZgyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Insert your code here\n",
        "'''"
      ],
      "metadata": {
        "id": "nSAHp5xhce8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rKEGqE3idhVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_images, train_labels,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "BjYbEXeGdatM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "vvLkJ8loddWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict values from test set\n",
        "y_pred = model.predict(test_images)\n",
        "#convert predictions classes to one hot vectors\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "#convert test observations to one hot vectors\n",
        "#y_true = np.argmax(test_labels)\n",
        "y_true = test_labels\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes,  target_names=class_names, digits=4))"
      ],
      "metadata": {
        "id": "TjTHrrx8dl5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "(to_Student)_Assignment_FashinMNIST_v2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}